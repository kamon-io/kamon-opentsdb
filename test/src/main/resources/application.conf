connector {
  env = ""

  oraReader {
    pool {
      jdbcUrl = "jdbc:oracle:thin:@//10.34.0.5:1521/mstat"

      username = mfmdataapp
      password = "mfmdataapp+16"

      fetchSize = 1000
      maximumPoolSize = 1
      poolName = "db-metadataReader"
    }
  }
}

LogActor {
  LogHtmlAndJS = debug
  LogHtml = info
  LogJavaScript = info
}

rmi-connector {
  port = 50001
  host = "10.100.0.19"

  message {
    serviceName = "ComfmdiMfmdMfmdOutMessageService"
  }

  message-status {
    serviceName = "ComfmdiMfmdMfmdOutMessageDlvEventService"
  }

  message-segment {
    serviceName = "ComfmdiMfmdMfmdOutMessageSegmentService"
  }
}

akka {
  # log-config-on-start = on
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  http.server {
    request-timeout = 30 seconds
    parallelism = 10
  }

  kafka {
    topic {
      outMessage = "OutMessage_RMI"
      dlvStatus = "DlvStatus_RMI"
      parseError = "ParseError_Test"
    }

    send-timeout = 1000 //msec

    producer {
      // default setting
      parallelism = 100

      kafka-clients {
        // change it to md-kafka.service.consul:9092 after refactoring kafka image!
        bootstrap.servers = "10.34.1.30:9092,10.34.1.31:9092,10.34.1.32:9092"
        acks = "all"
        client.id = "connectRMI"
      }
    }
  }
}

kamon {
  metric {
    # Time interval for collecting all metrics and send the snapshots to all subscribed actors.
    tick-interval = 1 seconds
  }

  opentsdb {
    http {
      parallelism = 1
      host = "bux.mfms"
      port = 4224
    }
  }

  modules {
    kamon-opentsdb {
      extension-class = "kamon.opentsdb.OpenTSDB_Http"
    }
  }
}


